{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import Augmentor as aug\n",
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import scipy\n",
    "\n",
    "from torch.utils import data\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.backends.cudnn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import scipy.io as io\n",
    "import scipy.misc as m\n",
    "import imageio as mio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run / prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for pix2pix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply bash script below to convert png to jpeg in gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in *.png ; do convert \"$i\" \"${i%.*}.jpg\" ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_str = '/home/sanityseeker/Documents/Datasets'\n",
    "# types = ['train', 'test', 'val']\n",
    "# nums = [2200, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, t in enumerate(types):\n",
    "#     p = aug.Pipeline(f'{base_str}/A/{t}/')\n",
    "#     p.ground_truth(f'{base_str}/B/{t}/')\n",
    "#     p.flip_left_right(probability=0.6)\n",
    "#     p.rotate(probability=0.7, max_left_rotation=25, max_right_rotation=25)\n",
    "#     p.rotate90(probability=0.1)\n",
    "#     p.zoom_random(probability=0.6, percentage_area=0.8)\n",
    "#     p.flip_top_bottom(probability=0.5)\n",
    "#     p.sample(nums[i], multi_threaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply commands below to move gt to separate folder and make gt named the same as train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv *_groundtruth\\_\\(1\\)* /home/sanityseeker/Documents/Datasets/B/train\n",
    "# rename \\_groundtruth\\_\\(1\\)\\_train\\_ train\\_original\\_ *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --dataroot ~/Documents/Datasets --name airports_default_lr --model pix2pix --batch_size 1 --num_threads 4 --lr_decay_iters 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(os.path.join(lol, 'codes', 'vko19bing_1-4.png'))\n",
    "# result = image.convert('P', palette=Image.ADAPTIVE)\n",
    "# result.putalpha(0)\n",
    "# colors = result.getcolors()\n",
    "\n",
    "# sorted(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airports_labels():\n",
    "    return np.asarray(\n",
    "    [\n",
    "        [0, 255, 0],  # 0 : green\n",
    "        [255, 255, 255],  # 1 : white\n",
    "        [255, 255, 0],  # 2 : yellow\n",
    "        [0, 255, 255],  # 3 : cyan\n",
    "        [0, 0, 255],  # 4 : blue\n",
    "        [0, 0, 0],  # 5 : black\n",
    "        [255, 0, 0],  # 6 :red\n",
    "        [255, 0, 255],  # 7 : purple\n",
    "        [0, 128, 128],  # 8 : teal\n",
    "        [128, 128, 0]  # 9 : olive\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(rgb_image):\n",
    "    def find_nearest_class(input, classes):\n",
    "        return np.argmin(np.linalg.norm(classes - input, axis=-1))\n",
    "    \n",
    "    classes = get_airports_labels()\n",
    "    mask = np.array(rgb_image, dtype=int)\n",
    "    label_mask = np.apply_along_axis(lambda a : find_nearest_class(a, classes), axis=-1, arr=mask)\n",
    "    return label_mask\n",
    "    \n",
    "def decode_label(label_img, n_classes=10, save_img_path=None):\n",
    "    label_colours = get_airports_labels()\n",
    "    label_mask = np.array(label_img)\n",
    "    r = label_mask.copy()\n",
    "    g = label_mask.copy()\n",
    "    b = label_mask.copy()\n",
    "    for ll in range(0, n_classes):\n",
    "        r[label_mask == ll] = label_colours[ll, 0]\n",
    "        g[label_mask == ll] = label_colours[ll, 1]\n",
    "        b[label_mask == ll] = label_colours[ll, 2]\n",
    "    rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))\n",
    "    rgb[:, :, 0] = r\n",
    "    rgb[:, :, 1] = g\n",
    "    rgb[:, :, 2] = b\n",
    "    img = Image.fromarray(rgb.astype('uint8'), 'RGB')\n",
    "    if save_img_path:\n",
    "        mio.imwrite(save_img_path, rgb)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_loop(image_name, train_imgs, train_labels, result_labels_decoded_path, \n",
    "              result_labels_encoded_path, result_labels_path, result_imgs_path, crop_num, rot_num, \n",
    "              random_flip_crop, random_rotation):    \n",
    "        img_train_path = os.path.join(train_imgs, image_name)\n",
    "        img_label_path = os.path.join(train_labels, image_name)        \n",
    "        \n",
    "        if not os.path.isfile(img_train_path):\n",
    "            return\n",
    "\n",
    "        img = Image.open(img_train_path)\n",
    "        label= Image.open(img_label_path)\n",
    "        \n",
    "        for i in range(rot_num):\n",
    "            seed = random.randint(0,2**32)\n",
    "            random.seed(seed)\n",
    "            rot_img = random_rotation(img)\n",
    "            random.seed(seed)\n",
    "            rot_label = random_rotation(label)\n",
    "            \n",
    "            rot_label_encoded = encode_label(rot_label)\n",
    "            if np.any(rot_label_encoded > 9):\n",
    "                raise ValueError\n",
    "            \n",
    "            rot_label_encoded = m.toimage(rot_label_encoded, high=rot_label_encoded.max(), low=rot_label_encoded.min())\n",
    "\n",
    "            for j in range(crop_num):\n",
    "                seed = random.randint(0,2**32)\n",
    "                random.seed(seed)\n",
    "                rot_cropped_img = random_flip_crop(rot_img)\n",
    "                random.seed(seed)\n",
    "                rot_cropped_label = random_flip_crop(rot_label)\n",
    "                random.seed(seed)\n",
    "                rot_cropped_label_encoded = random_flip_crop(rot_label_encoded)\n",
    "                \n",
    "                if np.any(np.array(rot_cropped_label_encoded) > 9):\n",
    "                    raise ValueError\n",
    "                \n",
    "                decode_label(rot_cropped_label_encoded, \n",
    "                             save_img_path=f'{result_labels_decoded_path}/_{image_name}_{i}_{j}.png')\n",
    "                \n",
    "                rot_cropped_img.save(f'{result_imgs_path}/_{image_name}_{i}_{j}.png')\n",
    "                rot_cropped_label.save(f'{result_labels_path}/_{image_name}_{i}_{j}.png') \n",
    "                mio.imwrite(f'{result_labels_encoded_path}/_{image_name}_{i}_{j}.png', np.array(rot_cropped_label_encoded))\n",
    "\n",
    "                \n",
    "def augment_data(data_path, prefix='train', crop_size=512, crop_scale=(0.5, 0.8), \n",
    "                 crop_num = 15, rot_num = 15, rotation_degrees=(3, 20)):\n",
    "    \n",
    "    train_imgs = os.path.join(data_path, prefix)\n",
    "    train_labels = os.path.join(data_path, f'{prefix}_masks')\n",
    "    result_imgs_path = os.path.join(train_imgs, f'augmented_{crop_size}')\n",
    "    result_labels_path = os.path.join(train_labels, f'augmented_{crop_size}')\n",
    "    result_labels_encoded_path = os.path.join(train_labels, f'labels_{crop_size}')\n",
    "    result_labels_decoded_path = os.path.join(train_labels, f'labels_decoded_{crop_size}')\n",
    "    \n",
    "    if not os.path.isdir(result_imgs_path):\n",
    "        os.makedirs(result_imgs_path)\n",
    "    if not os.path.isdir(result_labels_path):\n",
    "        os.makedirs(result_labels_path)\n",
    "    if not os.path.isdir(result_labels_encoded_path):\n",
    "        os.makedirs(result_labels_encoded_path)\n",
    "    if not os.path.isdir(result_labels_decoded_path):\n",
    "        os.makedirs(result_labels_decoded_path)\n",
    "\n",
    "    filenames = os.listdir(train_imgs)\n",
    "\n",
    "    center_crop = transforms.CenterCrop(crop_size)\n",
    "    random_rotation = transforms.RandomRotation(rotation_degrees, expand=False)\n",
    "    random_flip_crop = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomResizedCrop(size=crop_size, scale=crop_scale, interpolation=Image.NEAREST)\n",
    "    ])\n",
    "\n",
    "#     for i, image_name in enumerate(tqdm.tqdm_notebook(filenames))\n",
    "        \n",
    "    joblib.Parallel(n_jobs=-1, verbose=1)(joblib.delayed(body_loop)\n",
    "                                          (image_name, train_imgs, train_labels, result_labels_decoded_path, \n",
    "                                           result_labels_encoded_path, result_labels_path, result_imgs_path, \n",
    "                                           crop_num, rot_num, random_flip_crop, random_rotation) for image_name in tqdm.tqdm(filenames))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run:\n",
    "    data_path = '/home/sanityseeker/Documents/semantic-segmentation/data/'\n",
    "    for mode in ['train', 'test']:\n",
    "        augment_data(data_path=data_path, prefix=mode, crop_size=512, rot_num=3, crop_num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2eaca526b1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sample logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a sample down block\n",
    "# def make_conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "#     return [\n",
    "#         nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,  stride=stride, padding=padding, bias=False),\n",
    "#         nn.BatchNorm2d(out_channels),\n",
    "#         nn.ReLU(inplace=True)\n",
    "#     ]\n",
    "# self.down1 = nn.Sequential(\n",
    "#     *make_conv_bn_relu(in_channels, 64, kernel_size=3, stride=1, padding=1 ),\n",
    "#     *make_conv_bn_relu(64, 64, kernel_size=3, stride=1, padding=1 ),\n",
    "# )\n",
    "\n",
    "# # convolutions followed by a maxpool\n",
    "# down1 = self.down1(x)\n",
    "# out1 = F.max_pool2d(down1, kernel_size=2, stride=2)\n",
    "\n",
    "# # a sample up block\n",
    "# def make_conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "#     return [\n",
    "#         nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,  stride=stride, padding=padding, bias=False),\n",
    "#         nn.BatchNorm2d(out_channels),\n",
    "#         nn.ReLU(inplace=True)\n",
    "#     ]\n",
    "# self.up4 = nn.Sequential(\n",
    "#     *make_conv_bn_relu(128,64, kernel_size=3, stride=1, padding=1 ),\n",
    "#     *make_conv_bn_relu(64,64, kernel_size=3, stride=1, padding=1 )\n",
    "# )\n",
    "# self.final_conv = nn.Conv2d(32, num_classes, kernel_size=1, stride=1, padding=0 )\n",
    "\n",
    "# # upsample out_last, concatenate with down1 and apply conv operations\n",
    "# out   = F.upsample(out_last, scale_factor=2, mode='bilinear')  \n",
    "# out   = torch.cat([down1, out], 1)\n",
    "# out   = self.up4(out)\n",
    "\n",
    "# # final 1x1 conv for predictions\n",
    "# final_out = self.final_conv(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unet init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_: int, out: int):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "    link https://distill.pub/2016/deconv-checkerboard/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            self.block = nn.Sequential(\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
    "                                   padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNet11(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=32, pretrained=False):\n",
    "        \"\"\"\n",
    "        :param num_classes:\n",
    "        :param num_filters:\n",
    "        :param pretrained:\n",
    "            False - no pre-trained network used\n",
    "            True - encoder pre-trained with VGG11\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.encoder = models.vgg11(pretrained=pretrained).features\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Sequential(self.encoder[0],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv2 = nn.Sequential(self.encoder[3],\n",
    "                                   self.relu)\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            self.encoder[6],\n",
    "            self.relu,\n",
    "            self.encoder[8],\n",
    "            self.relu,\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            self.encoder[11],\n",
    "            self.relu,\n",
    "            self.encoder[13],\n",
    "            self.relu,\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            self.encoder[16],\n",
    "            self.relu,\n",
    "            self.encoder[18],\n",
    "            self.relu,\n",
    "        )\n",
    "\n",
    "        self.center = DecoderBlock(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv=True)\n",
    "        self.dec5 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv=True)\n",
    "        self.dec4 = DecoderBlock(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 4, is_deconv=True)\n",
    "        self.dec3 = DecoderBlock(256 + num_filters * 4, num_filters * 4 * 2, num_filters * 2, is_deconv=True)\n",
    "        self.dec2 = DecoderBlock(128 + num_filters * 2, num_filters * 2 * 2, num_filters, is_deconv=True)\n",
    "        self.dec1 = ConvRelu(64 + num_filters, num_filters)\n",
    "\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        conv4 = self.conv4(self.pool(conv3))\n",
    "        conv5 = self.conv5(self.pool(conv4))\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "\n",
    "        if self.num_classes > 1:\n",
    "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
    "        else:\n",
    "            x_out = self.final(dec1)\n",
    "\n",
    "        return x_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cuda(x):\n",
    "    return x.cuda(async=True) if torch.cuda.is_available() else x\n",
    "\n",
    "class LossMulti:\n",
    "    def __init__(self, jaccard_weight=0, class_weights=None, num_classes=10):\n",
    "        if class_weights is not None:\n",
    "            nll_weight = _cuda(\n",
    "                torch.from_numpy(class_weights.astype(np.float32)))\n",
    "        else:\n",
    "            nll_weight = None\n",
    "        self.nll_loss = nn.NLLLoss2d(weight=nll_weight)\n",
    "        self.jaccard_weight = jaccard_weight\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, outputs, targets):\n",
    "        loss = (1 - self.jaccard_weight) * self.nll_loss(outputs, targets)\n",
    "\n",
    "        if self.jaccard_weight:\n",
    "            eps = 1e-15\n",
    "            for cls in range(self.num_classes):\n",
    "                jaccard_target = (targets == cls).float()\n",
    "                jaccard_output = outputs[:, cls].exp()\n",
    "                intersection = (jaccard_output * jaccard_target).sum()\n",
    "\n",
    "                union = jaccard_output.sum() + jaccard_target.sum()\n",
    "                loss -= torch.log((intersection + eps) / (union - intersection + eps)) * self.jaccard_weight\n",
    "        return loss\n",
    "\n",
    "class CrossEntropyLoss2d(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CrossEntropyLoss2d, self).__init__()\n",
    "        self.nll_loss = nn.NLLLoss2d(weight, size_average)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        print(inputs.shape, type(inputs))\n",
    "        print(inputs)\n",
    "        print(targets.shape, type(targets))\n",
    "        print(targets)\n",
    "        return self.nll_loss(F.log_softmax(inputs), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirportsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Airports dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, labels_dir):\n",
    "        \"\"\"\n",
    "        Images and corresponding labels are supposed to have same filenames\n",
    "        Args:\n",
    "            img_dir (string): Path to images\n",
    "            labels_dir (string): Path to image labels\n",
    "        \"\"\"\n",
    "        self.names = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        \n",
    "        self.transform = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.names[idx])\n",
    "        label_path = os.path.join(self.labels_dir, self.names[idx])\n",
    "        img = self.transform(Image.open(img_path))\n",
    "        label = mio.imread(label_path)\n",
    "        if np.any(label > 9):\n",
    "            print(label_path)\n",
    "            print(np.unique(label))\n",
    "            raise ValueError\n",
    "        label = torch.LongTensor(label)\n",
    "        \n",
    "        sample = {'image': img, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(dataset, validation_split=.1, shuffle=True, batch_size=1, seed=1337):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/sanityseeker/Documents/semantic-segmentation/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_airports = AirportsDataset(img_dir=os.path.join(data_path, 'train', 'augmented_512'),\n",
    "                                    labels_dir=os.path.join(data_path, 'train_masks', 'labels_512'))\n",
    "aug_airports_test = AirportsDataset(img_dir=os.path.join(data_path, 'test', 'augmented_512'),\n",
    "                                    labels_dir=os.path.join(data_path, 'test_masks', 'labels_512'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_figures(figures, nrows = 1, ncols=1):\n",
    "#     \"\"\"Plot a dictionary of figures.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     figures : <title, figure> dictionary\n",
    "#     ncols : number of columns of subplots wanted in the display\n",
    "#     nrows : number of rows of subplots wanted in the figure\n",
    "#     \"\"\"\n",
    "\n",
    "#     fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "#     for ind,title in enumerate(figures):\n",
    "#         axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())\n",
    "#         axeslist.ravel()[ind].set_title(title)\n",
    "#         axeslist.ravel()[ind].set_axis_off()\n",
    "#     plt.tight_layout() # optional\n",
    "\n",
    "# for i in range(1):\n",
    "#     sample = aug_airports[i]\n",
    "#     print(i, sample['image'].shape, sample['label'].shape)\n",
    "#     a = transforms.ToPILImage()\n",
    "#     b = transforms.ToPILImage()\n",
    "#     a = a(sample['image'])\n",
    "#     b = b(sample['label'])\n",
    "# #     a.show()\n",
    "# #     b.show()\n",
    "#     images = [a, b]\n",
    "#     figures = {'im'+str(i): images[i] for i in range(len(images))}\n",
    "#     plot_figures(figures, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 1620 180\n"
     ]
    }
   ],
   "source": [
    "aug_airports_train, aug_airports_val = train_val_split(dataset=aug_airports)\n",
    "print(len(aug_airports), len(aug_airports_train), len(aug_airports_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation import validation_multi\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_event(log, step, **data):\n",
    "    data['step'] = step\n",
    "    data['dt'] = datetime.now().isoformat()\n",
    "    log.write(json.dumps(data, sort_keys=True))\n",
    "    log.write('\\n')\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, criterion, train_loader, valid_loader, validation, init_optimizer, n_epochs=None, fold=None,\n",
    "          num_classes=10):\n",
    "    \n",
    "    lr = args['lr']\n",
    "    optimizer = init_optimizer(lr)\n",
    "    \n",
    "    root = Path(args['root'])\n",
    "    model_path = root / 'model_{fold}.pt'.format(fold=fold)\n",
    "    if model_path.exists():\n",
    "        state = torch.load(str(model_path))\n",
    "        epoch = state['epoch']\n",
    "        step = state['step']\n",
    "        model.load_state_dict(state['model'])\n",
    "        print('Restored model, epoch {}, step {:,}'.format(epoch, step))\n",
    "    else:\n",
    "        epoch = 1\n",
    "        step = 0\n",
    "\n",
    "    save = lambda ep: torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'epoch': ep,\n",
    "        'step': step,\n",
    "    }, str(model_path))\n",
    "\n",
    "    report_each = 10\n",
    "    log = root.joinpath('train_{fold}.log'.format(fold=fold)).open('at', encoding='utf8')\n",
    "    valid_losses = []\n",
    "    for epoch in range(epoch, n_epochs + 1):\n",
    "        model.train()\n",
    "        random.seed()\n",
    "        tq = tqdm.tqdm(total=(len(train_loader) * args['batch_size']))\n",
    "        tq.set_description('Epoch {}, lr {}'.format(epoch, lr))\n",
    "        losses = []\n",
    "        tl = train_loader\n",
    "        try:\n",
    "            mean_loss = 0\n",
    "            for i, sample in enumerate(tl):\n",
    "                inputs = _cuda(sample['image'])\n",
    "#                 inputs = sample['image']\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    targets = _cuda(sample['label'])\n",
    "#                     targets = sample['label']\n",
    "                \n",
    "#                 print('inputs:')\n",
    "#                 print(inputs)\n",
    "#                 print(inputs.shape)\n",
    "                \n",
    "#                 print('targets:')\n",
    "#                 print(targets)\n",
    "#                 print(targets.type())\n",
    "#                 print(targets.shape)\n",
    "#                 print(targets.unique())\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "#                 print('outputs:')\n",
    "#                 print(outputs)\n",
    "#                 print(outputs.shape)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                optimizer.zero_grad()\n",
    "                batch_size = inputs.size(0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "                tq.update(batch_size)\n",
    "                losses.append(loss.item())\n",
    "                mean_loss = np.mean(losses[-report_each:])\n",
    "                tq.set_postfix(loss='{:.5f}'.format(mean_loss))\n",
    "                if i and i % report_each == 0:\n",
    "                    write_event(log, step, loss=mean_loss)\n",
    "            write_event(log, step, loss=mean_loss)\n",
    "            tq.close()\n",
    "            save(epoch + 1)\n",
    "            valid_metrics = validation(model, criterion, valid_loader, num_classes)\n",
    "            write_event(log, step, **valid_metrics)\n",
    "            valid_loss = valid_metrics['valid_loss']\n",
    "            valid_losses.append(valid_loss)\n",
    "        except KeyboardInterrupt:\n",
    "            tq.close()\n",
    "            print('Ctrl+C, saving snapshot')\n",
    "            save(epoch)\n",
    "            print('done.')\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['lr'] = 1e-3\n",
    "args['batch_size'] = 1\n",
    "args['root'] = data_path\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "train_loader, val_loader = train_val_split(dataset=aug_airports)\n",
    "test_loader = torch.utils.data.DataLoader(aug_airports_test, batch_size=1,\n",
    "                                          shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device(), torch.cuda.is_available(),\n",
    "torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching unet11 without pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanityseeker/env/lib/python3.6/site-packages/torch/nn/modules/loss.py:206: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see http://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "Epoch 3, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, epoch 3, step 3,240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, lr 0.001: 100%|██████████| 1620/1620 [22:33<00:00,  1.21it/s, loss=0.73133]\n",
      "Epoch 4, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.5844, average IoU: 0.3471, average Dice: 0.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.79237]\n",
      "Epoch 5, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.5613, average IoU: 0.3503, average Dice: 0.4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.42548]\n",
      "Epoch 6, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4808, average IoU: 0.4007, average Dice: 0.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.60826]\n",
      "Epoch 7, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4586, average IoU: 0.4148, average Dice: 0.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, lr 0.001: 100%|██████████| 1620/1620 [22:22<00:00,  1.21it/s, loss=0.55589]\n",
      "Epoch 8, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4339, average IoU: 0.4200, average Dice: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.20it/s, loss=0.51785]\n",
      "Epoch 9, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4656, average IoU: 0.4181, average Dice: 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.45500]\n",
      "Epoch 10, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4265, average IoU: 0.4565, average Dice: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.20it/s, loss=0.57385]\n",
      "Epoch 11, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3831, average IoU: 0.4829, average Dice: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.71235]\n",
      "Epoch 12, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.5618, average IoU: 0.3709, average Dice: 0.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, lr 0.001: 100%|██████████| 1620/1620 [22:22<00:00,  1.21it/s, loss=0.55908]\n",
      "Epoch 13, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3992, average IoU: 0.4703, average Dice: 0.5673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.39655]\n",
      "Epoch 14, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3554, average IoU: 0.4888, average Dice: 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.20it/s, loss=0.35687]\n",
      "Epoch 15, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3915, average IoU: 0.4634, average Dice: 0.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.41313]\n",
      "Epoch 16, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4534, average IoU: 0.4219, average Dice: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=1.29949]\n",
      "Epoch 17, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.7416, average IoU: 0.3493, average Dice: 0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, lr 0.001: 100%|██████████| 1620/1620 [22:22<00:00,  1.20it/s, loss=0.40826]\n",
      "Epoch 18, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3334, average IoU: 0.4995, average Dice: 0.5925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.24524]\n",
      "Epoch 19, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3850, average IoU: 0.4532, average Dice: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.28088]\n",
      "Epoch 20, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.3100, average IoU: 0.4996, average Dice: 0.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.55087]\n",
      "Epoch 21, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4125, average IoU: 0.4523, average Dice: 0.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.47439]\n",
      "Epoch 22, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4561, average IoU: 0.4097, average Dice: 0.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.16341]\n",
      "Epoch 23, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2990, average IoU: 0.5246, average Dice: 0.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.41926]\n",
      "Epoch 24, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.4055, average IoU: 0.4593, average Dice: 0.5538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.36161]\n",
      "Epoch 25, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2915, average IoU: 0.5417, average Dice: 0.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.32871]\n",
      "Epoch 26, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2844, average IoU: 0.5458, average Dice: 0.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.25258]\n",
      "Epoch 27, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2940, average IoU: 0.5423, average Dice: 0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.41701]\n",
      "Epoch 28, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2789, average IoU: 0.5660, average Dice: 0.6641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.19526]\n",
      "Epoch 29, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2785, average IoU: 0.5598, average Dice: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, lr 0.001: 100%|██████████| 1620/1620 [22:23<00:00,  1.21it/s, loss=0.22531]\n",
      "Epoch 30, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2785, average IoU: 0.5406, average Dice: 0.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, lr 0.001: 100%|██████████| 1620/1620 [22:24<00:00,  1.21it/s, loss=0.26725]\n",
      "Epoch 31, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2483, average IoU: 0.5765, average Dice: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, lr 0.001: 100%|██████████| 1620/1620 [22:25<00:00,  1.21it/s, loss=0.27937]\n",
      "Epoch 32, lr 0.001:   0%|          | 0/1620 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.2503, average IoU: 0.5697, average Dice: 0.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, lr 0.001:  19%|█▊        | 301/1620 [04:09<18:14,  1.21it/s, loss=0.30250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ctrl+C, saving snapshot\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = UNet11(num_classes=num_classes, pretrained=False)\n",
    "# model = unet(n_classes=10)\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=None).cuda()\n",
    "loss = LossMulti()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "train(\n",
    "        args,\n",
    "        init_optimizer=lambda l_rate: torch.optim.Adam(model.parameters(), lr=l_rate),\n",
    "        model=model,\n",
    "        criterion=loss,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        validation=validation_multi,\n",
    "        n_epochs=50,\n",
    "        fold=0,\n",
    "        num_classes=num_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching unet11 with pre-trained on VGG-11 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanityseeker/env/lib/python3.6/site-packages/torch/nn/modules/loss.py:206: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see http://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "Epoch 1, lr 0.001: 100%|██████████| 1620/1620 [22:31<00:00,  1.21it/s, loss=0.65994]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/csrc/generic/serialization.cpp:17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b7e3917c52d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-25-e8be5c45b03c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, criterion, train_loader, valid_loader, validation, init_optimizer, n_epochs, fold, num_classes)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwrite_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mvalid_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mwrite_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvalid_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-e8be5c45b03c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ep)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     }, str(model_path))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreport_each\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/csrc/generic/serialization.cpp:17"
     ]
    }
   ],
   "source": [
    "model = UNet11(num_classes=num_classes, pretrained=True)\n",
    "# model = unet(n_classes=10)\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=None).cuda()\n",
    "loss = LossMulti()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "train(\n",
    "        args,\n",
    "        init_optimizer=lambda l_rate: torch.optim.Adam(model.parameters(), lr=l_rate),\n",
    "        model=model,\n",
    "        criterion=loss,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        validation=validation_multi,\n",
    "        n_epochs=50,\n",
    "        fold=1,\n",
    "        num_classes=num_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

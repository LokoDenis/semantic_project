# ReadMe
## Semantic_project
The goal is to solve a semantic segmentation task for aerial imagery.

This repository contains two solutions:
- Calculate and ecode images using superpixels techniques (Meanshift etc.), describe images with features and then use Gradient Boosting Classifier. Written in C++.
- Using Unet-like neural net on augmented data. Written in Python using Pytorch (folder "dl").

Each solution can be further processed with CRF to factor outliers.

--

### Задача проекта
* Семантическая сегментация изображений --- это разделение изображений на группы пикселей, отвечающих разным типам объектов. Задача имеет практическую важность, например, в картографии, позволяя упростить процесс разметки карт. На данный момент существуют различные решения этой задачи, в основном основанные на применении различных подходов, основанных либо на машинном обучении, либо на сверточных нейронных сетях.
* Основные файлы данного репозитория -- работа в течение полугодия на втором курсе университета. Ноутбук в папке dl -- ее продолжение на третьем курсе.

### План работы (2 курс, 2017)

1) Написание утилиты, оценивающей качество разметки изображения.
Так как задачи публикуются в общей системе http://www2.isprs.org/commissions/comm3/wg4/semantic-labeling.html, неплохо было бы иметь свою утилитку--тулзу для оценки качества проделанной работы. Это позволит в реальном времени видеть, какие усовершенствования в программе ведут к улучшению результата, а какие --- нет.

2) Знакомство с основными методами сегментации изображения.
Можно рассмотреть следующие виды сегментации изображений: Meanshift/Quickshift, Efficient Graph-based, Turbopixel, SLIC. Идея в том, чтобы в дальнейшем работать не с отдельными пикселями, а с уже сгруппированными суперпикселями. Но для этого нужно быть уверенными в том, что каждый суперпиксель содержит в себе только точки одного класса разбиения. 

3) Выбор параметров для машинного обучения.
Чтобы обучаться, нужно выделить много характерных признаков. Для этого мы вспоминаем о таких вещах, как средние яркости, их дисперсии, различного рода ковариационные матрицы. Так как этого еще явно мало, сюда же добавляем возможность поэкспериментировать с линейными фильтрами и разностными признаками (предпочтительно Haar-like). Также можно работать и учитывая соседство пикселей (суперпикселей), для этого потребуется знание разных видов дескрипторов и методов кластеризации. В связке с подходом типа Bag of Words можно уменьшить размерность задачи, сделав выделяемые признаки более глобальными. Это поможет в ситуации, когда данных для обучения не так много.

4) Обучение.
Когда какие-то признакми уже выделены, можно попробовать пообучаться на классификаторе Random Forest или его аналогах.

5) Оценка обучения.
Вполне понятно, что нужно уметь оценивать качество самого обучения из рассчета того, насколько хорошо построенная модель будет работать на независимых данных. Для этого нужно ознакомиться с такими методами, хотя бы с кросс-вадидацией и пр.

6) Постобработка.
После обучения картинка все еще не имеет финальный вид, ведь возможны какие-то погрешности разбиения, смазанные границы, выбросы, например. Для "сглаживания углов" применяются несколько методов. Можно попробовать использовать здесь методы, основанные на Conditional Random Field (CRF) и минимизации энергии унарного и парного потенциалов. Возможных реализаций здесь очень много, в том числе можно использовать такие общие методы как Graph-cut, или же попробовать прикрутить сюда же уже отчасти знакомый SGM. Это интересено.

7) Ознакомление со статьями других людей.
Изучение данной темы на данный момент идет полным ходом. Поэтому имеет смысл ознакомиться хотя бы с десятком подобных работ, чтобы представлять, какие подходы на данный момент используются чаще всего и почему, что уже доказало свою эффективность или неэффективность. На основе таких данных определенно появятся дополнительные идеи, как можно улучшить свою реализацию. 

### Что сделано

1) Исследованы различные методы сегментации для преобработки изображений из базы. Ввиду того, что обучаться на пикселях довольно долго и не очень эффективно, было принято решение использовать суперпиксели в качестве объектов для обучения. Возникла задача выделять суперпиксели на изображении так, чтобы все пиксели в них принадлежали одним и тем же классам. Соответственно, сегменты в данном случае должны быть довольно небольшого размера. Таким образом, был выбран метод SLIC со средним количеством сегментов на изображение примерно 50000. Наглядное сравнение двух различных методов сегментации, SEED и SLIC.

2) После сегментирования изображений возникает задача описания данных сегментов. В моем случае, описание производится с помощью классов Pixel и SuperPixel, написанных на C++. Сегмент выражается с помощью средних значений и стандартных отклонений величин каналов, интенсивности, nDSM и nDVI пикселей, входящих в его состав. Данные классы описаны в файле pixel_classes.cpp

3) В качестве базы для обучения были взяты картинки 3, 5, 7, 11, 13, 15, 17, 21, 23, 26. Реализованы повороты на произвольный угол. Для составления обучающей выборки использовались повороты с шагом в 45 градусов. Итоговая обучающая выборка составляла приблизительно 4 миллиона суперпикселей.

4) Процесс обучения производился с помощью метода Gradient Boosted Trees. Данный метод показал себя более эффективным, нежели обычный Random Forest Classifier. Код обучения представлен на языке Python, файл train.py. 

5) После обучения полученная модель сохраняется для дальнейшего тестирования. Для целей оценки качества модели сделаны две основные вещи. Первое -- таблица .csv, включающая в себя confusion matrix, оценки precision, recall, f1, support для каждого класса, а также общая точность (файл evaluate.py) Второе -- получение изображения текущей сегментации. Для этого во время построения тестовой базы для каждого суперпикселя каждого изображения в yaml-файл сохраняется вектор его пикселей с координатами; в процессе тестрирования сохраняется yaml файл с предполагаемыми значениями классов суперпикселей. Далее с помощью программы draw.cpp строится и сохраняется предполагаемое изображение. Звучит довольно просто, но по ходу работы возникли некоторые технические сложности. В частности, (через энное количество часов) пришло осознание, что yaml файлы, генерируемые opencv на c++ и yaml файлы библиотек питона не ялвяются совместимыми между собой ввиду разных версий протоколов. Решение было найдено с помощью использования библиотек yaml-cpp и ruamel-yaml, а также составлением кода имеенно на c++ во избежании необходимости писать вручную конструкторы нестандартных типов для питона. Вдобавок к этому необходимо избегать появления в данных величин nan и пр. Как показала практика, они так или иначе всегда появляются по тем или иным причинам. Поэтому для вычисления mean и std были написаны свои функции, позволяющие не портить данные исключением невалидных строк и сохранять соответствие между двумя yaml файлами.

Некоторые таблицы результатов, модель и одна из картинок прилагаются в папке Samples. На примере 32-ой фотографии показан способ хранения данных и последующего восстановления изображения.

Текущий средний результат по точности при тестировании по пяти картинкам, не входящих в обучающую выборку, составил 84 процента.  

6) Направления развития. Полученные результаты позволяют сказать некоторые очевидные вещи. Во-первых, один из классов, clutter, распознается хуже всего, и почти всегда с довольно плохой точностью ввиду малого количества данных для его распознавания (река на одной из фотографий и островки "мусора" на других). Во-вторых, необходимо доработать/добавить учитывание контекста в плане соседей. В ходе работы была освоена идея метода построения графа на суперпикселях, но не реализована в настоящий момент. Также есть заготовки для добавления модели bag-of-words, но в настоящий момент исследование на релевантность добавления данного критерия к обучению не произведено. Данные методы вкупе с освоением сверточных нейросетей должны поднять точность и качество сегментации.   

### Who am I?
Работа ведется студентом ПМИ ФКН ВШЭ Беляковым Денисом под руководством к.ф-м.н. Горбачева Вадима. 

